# Whole-genome sequencing analysis pipeline for copy number, segmental aneuploidy, and allele balance inference

Author: Cintia Gómez-Muñoz

Created: January 9, 2026

Updated: January 12, 2026

---

This notebook documents the command-line workflow used to process whole-genome sequencing data and generate downstream analyses, including:

* chromosome copy number estimation
* detection of segmental aneuploidies
* allele balance ratio (ABR) calculation and visualization

Read alignment and primary processing were run on the **IFB Core Cluster**, while downstream post-processing and plotting were performed on a standard Linux workstation. Steps are presented in execution order and generate intermediate files reused in later sections.

## Directory structure

Raw sequencing reads are stored in a directory called `reads/raw/`.

A `jobs/` directory is used to store job-related files (logs, submission metadata).

```bash
mkdir -p reads/raw jobs
```

Additional directories are created as needed at each step of the pipeline.

## Read quality control and preprocessing

Two rounds of read quality assessment were performed: one on raw reads and one after read trimming.

### Quality control – round 1

Quality control was performed on the raw reads using **FastQC**.

```bash
mkdir -p quals/fastqc_rnd1
sbatch scripts/FastQC.slurm reads/raw/ quals/fastqc_rnd1
```

This step generates per-sample quality reports used to assess read quality, adapter content, and base composition prior to further processing.

Results from the **FastQC** analysis were aggregated using **MultiQC**.

```bash
sbatch scripts/MultiQC.slurm quals/fastqc_rnd1
mv multiqc_report.html multiqc_data
mv multiqc_data quals/multiqc_rnd1/
```

This step produces a consolidated quality control report summarizing per-sample **FastQC** metrics for the raw reads.

### Read trimming

Adapter removal and quality trimming were performed using **Trimmomatic**.

```bash
mkdir -p reads/paired reads/unpaired
sbatch scripts/Trimming.slurm
```

**Trimmomatic** was run with the following parameters: `ILLUMINACLIP:files/NexteraPE-PE.fa:2:30:10 HEADCROP:15 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36`.

Trimming statistics were extracted from the **Trimmomatic** log files to summarize read retention after preprocessing.

The command below parses the **Trimmomatic** stderr output generated by the **SLURM** job and produces a tab-delimited summary file containing, for each sample:

* total input read pairs
* surviving paired reads
* forward-only surviving reads
* reverse-only surviving reads
* dropped reads

**Note:** Replace the numeric suffix in the job error file (`trimming.err.00000000`) with the appropriate job identifier.

```bash
mkdir -p out_data
echo -e "Sample\tInput_Read_Pairs\tBoth\tBoth_per\tForward_Only\tForward_Only_per\tReverse_Only\tReverse_Only_per\tDropped\tDropped_per" > out_data/trimming_stats.txt
paste <(sed '/bash/d ; /TrimmomaticPE/d ; /Using/d ; /phred33/d ; /Input Read Pairs/d ; s/ ILLUMINACLIP.*// ; s/.*\/// ; s/_.*//' jobs/trimming.err.00000000) \
<(grep "Input Read Pairs" jobs/trimming.err.00000000 | sed 's/Input Read Pairs: // ; s/ Both Surviving: /\t/ ; s/ Forward Only Surviving: /\t/ ; s/ Reverse Only Surviving: /\t/ ; s/ Dropped: /\t/ ') | sort >> out_data/trimming_stats.txt
```

The resulting file (`out_data/trimming_stats.txt`) is used for downstream quality control summaries and reporting.

### Quality control – round 2

A second round of quality control was performed on the trimmed reads to verify the effectiveness of the trimming step.

```bash
mkdir -p quals/fastqc_rnd2
sbatch scripts/FastQC.slurm reads/paired/ quals/fastqc_rnd2
sbatch scripts/MultiQC.slurm quals/fastqc_rnd2
mv multiqc_report.html multiqc_data
mv multiqc_data quals/multiqc_rnd2/
```

The resulting report provides a post-trimming overview of read quality across all samples.

## Read alignment

### Alignment and copy-number pipeline execution

Read alignment and downstream variant- and copy-number–related processing were performed using the [poly_CCN_and_VC](https://github.com/CintiaG/poly_CCN_and_VC) pipeline.

The pipeline was downloaded and configured following the instructions provided in the corresponding repository.

```bash
conda activate envs/snakemake/
mv reads/paired/* poly_CCN_and_VC/data/
cd poly_CCN_and_VC/
nohup snakemake --profile chrom_cp_nb &
```

The workflow was executed using **Snakemake** on the **IFB Core Cluster**, producing aligned reads and intermediate files required for chromosome copy number estimation and allele balance analyses.

**SLURM** standard output and error files generated during the analysis were moved to a dedicated directory for organization and record keeping.

```bash
mkdir -p results/slurm_out/
mv slurm-*.out slurm-*.err results/slurm_out/
```

After completion of the alignment workflow, input read files were returned to their original location and result files were moved to an upper-level directory. This was done to keep the `poly_CCN_and_VC` directory clean and to avoid accidental overwriting when re-running the pipeline.

```bash
cd ..
mv poly_CCN_and_VC/data/* reads/paired/
mv poly_CCN_and_VC/results .
```

### Alignment statistics

Alignment statistics were computed for all **BAM** files using **samtools flagstat**.

```bash
screen -SL flagstat -Logfile results/logs/flagstat.log \
bash -c 'ls results/bam/*.bam | parallel "samtools flagstat {} > {.}_flagstat.txt"'
```

This command computes basic alignment metrics (e.g. total reads, mapped reads, properly paired reads) for each **BAM** file in parallel. Individual reports are written next to their corresponding **BAM** files, and execution logs are saved to `results/logs/flagstat.log`.

A summary table of alignment statistics was generated from the individual **samtools flagstat** output files.


```bash
echo -e "Sample\tMapped_reads\tMapped_reads_percent" > out_data/alignment_stats.txt
ls results/bam/*_flagstat.txt | parallel \
"paste <(echo '{/}' | sed 's/_.*//') \
<(grep '0 mapped (' {} | sed 's/ .*//') \
<(grep '0 mapped (' {} | sed 's/.*(// ; s/ .*//')" \
>> out_data/alignment_stats.txt
```

The resulting file (`out_data/alignment_stats.txt`) contains, for each sample, the number and percentage of mapped reads.

## Sequencing depth calculation

Sequencing depth was computed using **BEDTools** at two resolutions:

* base-level depth across the genome, and
* average depth in 30 kb windows.

Depth histograms were also generated.

This step uses a precomputed **BED** file of 30 kb genomic windows provided in the `poly_CCN_and_VC` repository.

```bash
mkdir -p results/bedtools/
sbatch scripts/Bedtools.slurm results/bam/ results/bedtools/
```

### Compile per-sample outputs

From this point on, computing was performed on a standard Linux workstation.

Per-sample depth summaries were concatenated into combined, sample-annotated tables for downstream analysis and plotting.

#### Depth per 30 kb windows

```bash
ls results/bedtools/*depth_per_30Kb.bed | parallel -j 1 \
'awk -v s="{/}" '\''{print s "\t" $0}'\'' {}' | sed 's/_depth_per_30Kb.bed//' \
> out_data/sequencing_depth_per_30Kb.bed
```

ls bedtools/*depth_per_30Kb.bed | parallel -j 1 'awk -v s="{/}" '\''{print s "\t" $0}'\'' {}' | sed 's/_depth_per_30Kb.bed//'


#### Depth histograms

```bash
ls results/bedtools/*histograms.bed | parallel -j 1 \
'awk -v s="{/}" '\''{print s "\t" $0}'\'' {}' | sed 's/_histograms.bed//' \
> out_data/sequencing_histograms.bed
```

The resulting files are:

* `out_data/sequencing_depth_per_30Kb.bed`: depth values per 30 kb window, with the sample name in the first column.
* `out_data/sequencing_histograms.bed`: per-sample depth histogram values, with the sample name in the first column.

## Summarize sequencing, QC, and alignment statistics

Trimming statistics (**Trimmomatic**), post-trimming QC metrics (**FastQC/MultiQC**), and alignment statistics (**samtools flagstat** summary) were combined into a single per-sample summary table.

```bash
Rscript scripts/get_sequencing_stats.R \
  out_data/trimming_stats.txt \
  quals/multiqc_rnd2/multiqc_fastqc.txt \
  out_data/alignment_stats.txt \
  out_data/sequencing_stats.txt
```

The resulting file (`out_data/sequencing_stats.txt`) contains per-sample sequencing and mapping summary metrics and is used for downstream reporting and visualization.

## Post-processing and visualization

### Estimation of genome-wide depth mode

The modal sequencing depth (“genome depth mode”) was estimated from the depth histogram using an in-house script (`plot_depth.R`). For each sample, the script identifies the depth bin corresponding to the maximum frequency in the genome-wide histogram (`Chr == "genome"`), after excluding low-depth bins (Depth ≤ 10) to reduce noise.

The third argument is a **prefix** used to label outputs (e.g. when processing multiple sequencing projects). In this notebook, we use the prefix `sequencing`. The fourth argument specifies the **maximum depth threshold** used for filtering and should be adjusted according to the project.

This modal depth typically correlates with the **baseline ploidy**, i.e. the most frequent chromosome copy number state across the genome. The script requires a metadata information file (`sequencing.csv`) that up to this point requires only the `Sample` information (see Required sample information table below).

```bash
Rscript scripts/plot_depth.R \
  out_data/sequencing_histograms.bed \
  files/sequencing.csv \
  files/chrom_index_cen.txt \
  sequencing \
  300
```

This step generates:

* per-sample depth histogram plots in `figures/histograms_sequencing/`
* a per-sample table of modal depths: `out_data/sequencing_depth_mode.csv`

**Note:** copy the `Depth_mode` column from `out_data/sequencing_depth_mode.csv` to the `sequencing.csv` metadata file for the next step.

## Segmental aneuploidy detection

### Algorithm overview

Segmental aneuploidies were detected using sequencing depth profiles computed in 30 kb windows, following an approach adapted from the **ScRAP** algorithm (O’Donnell et al. 2023; see [aneuploidy_detection](https://github.com/SAMtoBAM/aneuploidy_detection)), with several modifications introduced to better match our sequencing data and analysis goals.

For each sample, sequencing depth values are converted into copy number estimates using the genome-wide depth mode and the baseline ploidy. Windows with depth ≤ 10 or exceeding a user-defined maximum are excluded to reduce noise and extreme outliers.

Copy number per window is computed as:

> Copies = Depth / (Depth_mode / Base_ploidy)

For each chromosome, consecutive windows with copy number values deviating from the baseline ploidy are grouped into contiguous segments, allowing for gaps up to the window size (30 kb). Deviations are classified as:

* **increase**
* **decrease**
* **normal**

Thresholds are defined as a function of the baseline ploidy to account for different ploidy states.

Segments spanning fewer than five consecutive windows are discarded. For chromosomes containing multiple deviating regions, intervening normal-depth segments are also extracted to enable segmentation of complex aneuploidies.

For each detected segment and chromosome, copy number is summarized using the median copy number across windows. Genome-wide ploidy is estimated as the **size-weighted mean copy number** across all chromosomes and segments. Detected aneuploidies are annotated, optionally corrected using user-defined manual adjustments, and visualized together with depth histograms and chromosome-scale copy number profiles.

### Algorithm modifications relative to the original ScRAP implementation

Several modifications were introduced relative to the original **ScRAP** implementation to better suit our data and sequencing characteristics.

#### Copy number deviation thresholds

In the original **ScRAP** algorithm, the hard threshold for copy number deviation is defined as:

> 0.7 × (1 / n)

where n is the baseline ploidy. For example, in a triploid genome this corresponds to a deviation of ± 0.21 relative to the median genome-wide coverage.

In practice, we use a slightly adjusted threshold of **± 0.23 for triploid samples**, which provided more stable segmentation in our datasets.

#### Telomeric window filtering

To avoid repetitive mapping artifacts at chromosome ends, ScRAP removes approximately the first and last 15 kb of each chromosome.

In this workflow, we instead remove the **first and last three 30 kb windows** of each chromosome, corresponding to telomeric regions. This empirical adjustment improved robustness in depth-based copy number estimation.

#### Handling of low-coverage regions

The original ScRAP implementation excludes low-coverage regions (defined as < 10 % of genome-wide coverage) prior to grouping windows into segments.

Here, we **retain all windows during the grouping step**. Low- and high-coverage windows are filtered only during region summarization and visualization. This approach did not affect segment detection in our data and simplified downstream interpretation.

#### Minimum segment size

Only regions spanning **more than five consecutive windows** are retained, corresponding to a minimum size of approximately **70 kb** before post-filtering. After post-filtering to avoid overlapping segments, the smallest detectable complex aneuploidy is approximately **60 kb**.

#### Sliding window size and gap tolerance

While the original implementation uses a smaller sliding window, we found that a **30 kb window size and gap tolerance** provided improved stability for detecting both chromosome-scale and segmental aneuploidies in our sequencing data.

Overall, these modifications preserve the conceptual framework of the original **ScRAP** algorithm while adapting thresholding, filtering, and segmentation parameters to better match the resolution and noise characteristics of our datasets.

### Required sample information table

This step requires a sample information table (`.csv`) providing per-sample metadata and ploidy-related parameters used for normalization, annotation, and plotting.

The sample information file (e.g. `files/sequencing.csv`) must contain **at least** the following columns:

* `Sample` — sample identifier. Must exactly match the sample names used in `out_data/*`.
* `Base_ploidy` — Baseline ploidy of the sample (e.g. inferred from flow cytometry or prior biological knowledge). Used to normalize sequencing depth and to define copy-number thresholds.
* `Depth_mode` — Modal genome-wide sequencing depth, computed in the previous step using (`plot_depth.R`). Used to convert depth values into copy number estimates.

### Optional columns

The following columns are optional but supported by the pipeline:

* `Code` — Short sample identifier used for plotting and file naming. If not provided or empty, the script automatically falls back to using Sample.
* `Miss_Chr` — Manual copy-number correction string (e.g. `+1*3;-1*7`). Can be left empty on the first run and filled during manual curation to correct systematic mis-detections.
* `Mean_ploidy`, `Rounded_ploidy` — Optional ploidy summary values (e.g. from independent estimates). Used only for plot titles when available; if absent, plots display the baseline ploidy (Base_ploidy) instead.

The script is robust to the absence of optional columns and will automatically adjust plot annotations and labels accordingly.

### Copy number visualization in 30 kb windows

Copy number profiles (30 kb windows) and centromere-aware plots were generated using an in-house script.

The third argument is a prefix used to label outputs (here: `sequencing`).
The fourth argument (`300`) is the **maximum depth** threshold used for filtering (adjust per dataset).
The last argument (`6`) specifies the **maximum copy number** displayed in the plots.

```bash
Rscript scripts/plot_copies.R \
  out_data/sequencing_histograms.bed \
  out_data/sequencing_depth_per_30Kb.bed \
  files/sequencing.csv \
  files/chrom_index_cen.txt \
  sequencing \
  300 \
  6
```

**Note:** To enable downstream visualization and annotation (e.g. in ABR plots), `Bioinfo_ploidy` column, contained in `out_data/sequencing_copy_number.csv` should be added to the sample metadata file (`files/sequencing.csv`).

## Allele balance ratio calculation

Allele balance ratios (ABR) were computed from variant call files (**VCFs**) generated by the `poly_CCN_and_VC` pipeline.

### Renaming VCF files

By default, `poly_CCN_and_VC` uses the prefix `polyploid` for output files. To keep naming consistent with the rest of this notebook and downstream analyses, VCF files were renamed to use the same sequencing prefix (`sequencing`) used throughout the workflow.

```bash
cd results/vcf/
rename 's/polyploid/sequencing/' *
cd ../../
```

This command renames all VCF-related files accordingly, for example:

* `polyploid_strains.vcf.gz` → `sequencing_strains.vcf.gz`
* `polyploid_strains.vcf.gz.tbi` → `sequencing_strains.vcf.gz.tbi`
* `merged_polyploid_strains.g.vcf.gz.tbi` → `merged_sequencing_strains.g.vcf.gz.tbi`

This step ensures consistent file naming across analyses and prevents ambiguity when processing multiple sequencing projects.

### Allele depth and read depth

ABR was calculated by extracting allele depth (AD) and total read depth (DP) information from the renamed **VCF** files using **BCFtools**.

```bash
screen -SL bcf_tools -Logfile results/logs/calculate_AD.log \
bash scripts/calculate_AD.sh results/vcf/sequencing_strains.vcf.gz out_data/

screen -SL bcf_tools -Logfile results/logs/calculate_DP.log \
bash scripts/calculate_DP.sh results/vcf/sequencing_strains.vcf.gz out_data/
```

These commands generate plain-text tables containing per-variant AD and DP values for all samples.

### Conversion to FST format

To improve input/output performance for downstream analyses and plotting, the resulting text files were converted to **fst** format using the `fst` R package.

```bash
Rscript scripts/convert2fst.R out_data/sequencing_strains_AD.txt
Rscript scripts/convert2fst.R out_data/sequencing_strains_DP.txt
```

The resulting `.fst` files are used in subsequent steps for efficient calculation and visualization of allele balance ratios.

### Calculate allele balance ratio (ABR)

**ABR** values were computed using an in-house script (`allele_balance_ratio.R`) by combining allele depth (AD) and total depth (DP) information. For each variant and sample, allele-specific ratios were calculated and only alleles with **0.125 < ABR < 0.875** were retained.

```bash
screen -SL ratio -Logfile results/logs/allele_balance.log \
Rscript scripts/allele_balance_ratio.R \
  out_data/sequencing_strains \
  files/chrom_index_cen.txt
```

This creates a file `sequencing_strains_ABR.fst` a table with the compiled **AD**, **DP** and **ABR** information.

## Final visualization

Allele balance ratio (ABR) and copy-number profiles were combined in a final set of diagnostic plots using an in-house script (`plot_allele_balance_ratio.R`). For each sample, the script generates a multi-panel figure showing: (i) the genome-wide copy-number histogram, (ii) the 30 kb window copy-number profile with detected segments, (iii) the genome-wide ABR distribution, and (iv) ABR values along the genome.

```bash
Rscript scripts/plot_allele_balance_ratio.R \
  files/sequencing.csv \
  out_data/sequencing_strains_ABR.fst \
  out_data/sequencing_histograms_aneu.csv \
  out_data/sequencing_depth_per_aneu.csv \
  files/chrom_index_cen.txt \
  out_data/sequencing_copy_number_aneu.csv \
  out_data/sequencing_regions_aneu.csv \
  sequencing \
  6
```

Heterozygous-site counts and plots were computed using variants with 2–3 alleles (sites with >3 alleles were excluded).
